{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "import pkg_resources\r\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "# import json\r\n",
    "# import string\r\n",
    "# import re\r\n",
    "\r\n",
    "# with open('dataset/1-gram.json') as fopen:\r\n",
    "#     myfile = json.load(fopen)\r\n",
    "\r\n",
    "# with open(\"dataset/malay-words.txt\", \"w\", encoding=\"utf-8\") as text_file:\r\n",
    "#     j=1\r\n",
    "#     for i in myfile:\r\n",
    "#         # n = i.strip(string.punctuation)\r\n",
    "#         j+=1\r\n",
    "#         n = re.sub(r'[^\\w\\s]','',i)\r\n",
    "#         if j >= 248787:\r\n",
    "#             n = n.rstrip(\"\\n\")\r\n",
    "\r\n",
    "#         text_file.write(f'{n} {myfile[i]}\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "# import json\r\n",
    "# import string\r\n",
    "# import re\r\n",
    "# from collections import Counter\r\n",
    "\r\n",
    "# with open('dataset/dumping-wiki-6-july-2019.json') as fopen:\r\n",
    "#     myfile = json.load(fopen)\r\n",
    "\r\n",
    "# corpus = []\r\n",
    "# with open(\"dataset/malay-words.txt\", \"w\", encoding=\"utf-8\") as text_file:\r\n",
    "#     for line in myfile:\r\n",
    "#         line = line.replace('\\n', ' ').replace('\\t', ' ').lower()\r\n",
    "#         line = re.sub('[^a-z ]', ' ', line)\r\n",
    "#         text_file.write(f'{line}\\n')\r\n",
    "#     # tokens = line.split(' ')\r\n",
    "#     # tokens = [token for token in tokens if len(token) > 0]\r\n",
    "#     # corpus.extend(tokens)\r\n",
    "\r\n",
    "# # corpus = Counter(corpus)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "# from symspellpy import SymSpell\r\n",
    "\r\n",
    "# sym_spell = SymSpell()\r\n",
    "# corpus_path = 'dataset/malay-words.txt'\r\n",
    "# sym_spell.create_dictionary(corpus_path)\r\n",
    "\r\n",
    "# print(sym_spell.words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "# # build symspell tree \r\n",
    "# sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\r\n",
    "# #loading dictionary/lexicon\r\n",
    "# dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "# # term_index is the column of the term and count_index is the\r\n",
    "# # column of the term frequency\r\n",
    "# sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\r\n",
    "\r\n",
    "# # lookup suggestions for single-word input strings\r\n",
    "# input_term = \"sms\"  # misspelling of \"members\"\r\n",
    "# # max edit distance per lookup\r\n",
    "# print(\"Misspelled Word - \",input_term)\r\n",
    "# # (max_edit_distance_lookup <= max_dictionary_edit_distance)\r\n",
    "# suggestions = sym_spell.lookup(input_term, Verbosity.CLOSEST,\r\n",
    "#                                max_edit_distance=2)\r\n",
    "# # display suggestion term, term frequency, and edit distance\r\n",
    "# print(\"Best Candidate - \")\r\n",
    "# for suggestion in suggestions:\r\n",
    "#     print(suggestion)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "# from dataset.word import words \r\n",
    "# with open(\"dataset/malay-words.txt\", \"w\", encoding=\"utf-8\") as text_file:\r\n",
    "#     for w in words:\r\n",
    "#         text_file.write(f'{w}\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "with open('dataset/positive_words_ms.txt') as f:\r\n",
    "    pos_words1 = f.readlines()\r\n",
    "\r\n",
    "f.close()\r\n",
    "\r\n",
    "for i in range(len(pos_words1)):\r\n",
    "    pos_words1[i] = pos_words1[i].rstrip(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "with open('dataset/negative_words_ms.txt') as f:\r\n",
    "    neg_words1 = f.readlines()\r\n",
    "\r\n",
    "f.close()\r\n",
    "\r\n",
    "for i in range(len(neg_words1)):\r\n",
    "    neg_words1[i] = neg_words1[i].rstrip(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "import json\r\n",
    "\r\n",
    "with open('dataset/sentiment.json') as fopen:\r\n",
    "    myfile = json.load(fopen)\r\n",
    "\r\n",
    "neg_words2 = myfile['negative']\r\n",
    "pos_words2 = myfile['positive']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "neg_words = np.unique(neg_words1+neg_words2)\r\n",
    "pos_words = np.unique(pos_words1+pos_words2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\r\n",
    "from collections import Counter\r\n",
    "import string\r\n",
    "import re\r\n",
    "import stopwordsiso as sw\r\n",
    "\r\n",
    "# download required library from nltk\r\n",
    "# nltk.download('punkt')\r\n",
    "\r\n",
    "# create stemmer for bahasa\r\n",
    "factory = StemmerFactory()\r\n",
    "stemmer = factory.create_stemmer()\r\n",
    "\r\n",
    "# stop words consist of malay, indo, english\r\n",
    "stop_words_main = list(sw.stopwords([\"ms\", \"id\", \"en\"]))\r\n",
    "# custom stopwords such as shortform\r\n",
    "stop_words_custom = ['kau', 'yg', 'mcm', 'gak', 'nak', 'ni', 'tu', 'la', 'je', 'kat', 'ya', 'dgn', 'tau', 'org', 'rt', 'aja', 'nk', 'dah',\r\n",
    "                        'orang', 'sy', 'ga', 'kalo', 'kena']\r\n",
    "STOP_WORDS = np.unique(stop_words_main+stop_words_custom)\r\n",
    "\r\n",
    "def remove_emoji(text):\r\n",
    "    emoji_pattern = re.compile(\"[\"\r\n",
    "                           u\"\\U0001F600-\\U0001F64F\" # emoticons\r\n",
    "                           u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\r\n",
    "                           u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\r\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\r\n",
    "                           u\"\\U00002702-\\U000027B0\"\r\n",
    "                           u\"\\U000024C2-\\U0001F251\"\r\n",
    "                           \"]+\", flags=re.UNICODE)\r\n",
    "    return emoji_pattern.sub(r'', text)\r\n",
    "\r\n",
    "def text_preprocessing(text):\r\n",
    "\r\n",
    "    # remove numbers\r\n",
    "    text = re.sub(r'\\d+', '', text)\r\n",
    "\r\n",
    "    # remove links\r\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\r\n",
    "\r\n",
    "    # remove word with tweethandle @name\r\n",
    "    text = re.sub('[^ ]*@[^ ]*', '', text)\r\n",
    "\r\n",
    "    # remove emoji\r\n",
    "    text = remove_emoji(text)\r\n",
    "\r\n",
    "    # tokennization\r\n",
    "    tokens = word_tokenize(text)\r\n",
    "\r\n",
    "    # remove punctuation\r\n",
    "    words = []\r\n",
    "    for token in tokens:\r\n",
    "        if token not in string.punctuation:\r\n",
    "            # temp = stemmer.stem(token)\r\n",
    "            words.append(token)\r\n",
    "\r\n",
    "    # # remove stopwords\r\n",
    "    # cleaned = []\r\n",
    "    # for word in words:\r\n",
    "    #     if word not in STOP_WORDS:\r\n",
    "    #         cleaned.append(word)\r\n",
    "\r\n",
    "    # join all words into a complete sentence \r\n",
    "    complete_sentence = ' '.join([str(word) for word in words])\r\n",
    "\r\n",
    "    # remove extra line spaces between words in a sentence\r\n",
    "    complete_sentence = \" \".join(complete_sentence.split())\r\n",
    "    \r\n",
    "    return complete_sentence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "text = \"Ironinya, penuntut universiti yang tanpa sebarang paksaan hadir ke program pro pembangkang dihalang, malah tindakan disiplin diambil.\"\r\n",
    "\r\n",
    "text_preprocessing(text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Ironinya penuntut universiti yang tanpa sebarang paksaan hadir ke program pro pembangkang dihalang malah tindakan disiplin diambil'"
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "def evaluate(text):\r\n",
    "\r\n",
    "    tokens = word_tokenize(text)\r\n",
    "\r\n",
    "    value = 0\r\n",
    "    for token in tokens:\r\n",
    "        if token in pos_words:\r\n",
    "            value+=1\r\n",
    "        elif token in neg_words:\r\n",
    "            value+=-1\r\n",
    "    \r\n",
    "    if value > 0:\r\n",
    "        result = 1\r\n",
    "    elif value < 0:\r\n",
    "        result = -1\r\n",
    "    else:\r\n",
    "        result = 0\r\n",
    "\r\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "evaluate(text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "test_data1 = pd.read_csv('dataset/news-test-data.csv')\r\n",
    "test_data1.loc[test_data1['label'] == 'Neutral', 'label'] = 0\r\n",
    "test_data1.loc[test_data1['label'] == 'Positive', 'label'] = 1\r\n",
    "test_data1.loc[test_data1['label'] == 'Negative', 'label'] = -1\r\n",
    "test_data1.loc[test_data1['label'] == 'negative', 'label'] = -1\r\n",
    "test_data1['label'] = test_data1['label'].astype('int64')\r\n",
    "test_data1 = test_data1[['text', 'label']]\r\n",
    "print(test_data1.head(10))\r\n",
    "print(len(test_data1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                text  label\n",
      "0  Permohonan ini juga bertujuan memohon penjelas...      1\n",
      "1  Projek ini bukti komitmen berterusan kerajaan ...      1\n",
      "2  Menerusi pembentangan Bajet 2018 yang lalu, ke...      1\n",
      "3  Berdasarkan kualiti jawapan calon, 27 peratus ...      0\n",
      "4  Pada masa sama, kerajaan negeri juga telah bua...      1\n",
      "5  Kita bawa pembangunan, bukan sahaja untuk Saba...      1\n",
      "6  Harapan kita agar isu berkaitan golongan muda ...      1\n",
      "7  Kesan daripada penyemakan ini antaranya membab...      0\n",
      "8  Kalau dah bersara dan tiada kaitan lagi dengan...      1\n",
      "9  Kesediaan negara-negara ITRC untuk mematuhi ko...      1\n",
      "3688\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "text_cleaning = lambda x: text_preprocessing(x)\r\n",
    "test_data1['cleaned_text'] = pd.DataFrame(test_data1['text'].apply(text_cleaning))\r\n",
    "test_data1.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permohonan ini juga bertujuan memohon penjelas...</td>\n",
       "      <td>1</td>\n",
       "      <td>Permohonan ini juga bertujuan memohon penjelas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Projek ini bukti komitmen berterusan kerajaan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Projek ini bukti komitmen berterusan kerajaan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menerusi pembentangan Bajet 2018 yang lalu, ke...</td>\n",
       "      <td>1</td>\n",
       "      <td>Menerusi pembentangan Bajet yang lalu kerajaan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berdasarkan kualiti jawapan calon, 27 peratus ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Berdasarkan kualiti jawapan calon peratus calo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pada masa sama, kerajaan negeri juga telah bua...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pada masa sama kerajaan negeri juga telah buat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kita bawa pembangunan, bukan sahaja untuk Saba...</td>\n",
       "      <td>1</td>\n",
       "      <td>Kita bawa pembangunan bukan sahaja untuk Sabah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harapan kita agar isu berkaitan golongan muda ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Harapan kita agar isu berkaitan golongan muda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kesan daripada penyemakan ini antaranya membab...</td>\n",
       "      <td>0</td>\n",
       "      <td>Kesan daripada penyemakan ini antaranya membab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kalau dah bersara dan tiada kaitan lagi dengan...</td>\n",
       "      <td>1</td>\n",
       "      <td>Kalau dah bersara dan tiada kaitan lagi dengan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kesediaan negara-negara ITRC untuk mematuhi ko...</td>\n",
       "      <td>1</td>\n",
       "      <td>Kesediaan negara-negara ITRC untuk mematuhi ko...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Permohonan ini juga bertujuan memohon penjelas...      1   \n",
       "1  Projek ini bukti komitmen berterusan kerajaan ...      1   \n",
       "2  Menerusi pembentangan Bajet 2018 yang lalu, ke...      1   \n",
       "3  Berdasarkan kualiti jawapan calon, 27 peratus ...      0   \n",
       "4  Pada masa sama, kerajaan negeri juga telah bua...      1   \n",
       "5  Kita bawa pembangunan, bukan sahaja untuk Saba...      1   \n",
       "6  Harapan kita agar isu berkaitan golongan muda ...      1   \n",
       "7  Kesan daripada penyemakan ini antaranya membab...      0   \n",
       "8  Kalau dah bersara dan tiada kaitan lagi dengan...      1   \n",
       "9  Kesediaan negara-negara ITRC untuk mematuhi ko...      1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Permohonan ini juga bertujuan memohon penjelas...  \n",
       "1  Projek ini bukti komitmen berterusan kerajaan ...  \n",
       "2  Menerusi pembentangan Bajet yang lalu kerajaan...  \n",
       "3  Berdasarkan kualiti jawapan calon peratus calo...  \n",
       "4  Pada masa sama kerajaan negeri juga telah buat...  \n",
       "5  Kita bawa pembangunan bukan sahaja untuk Sabah...  \n",
       "6  Harapan kita agar isu berkaitan golongan muda ...  \n",
       "7  Kesan daripada penyemakan ini antaranya membab...  \n",
       "8  Kalau dah bersara dan tiada kaitan lagi dengan...  \n",
       "9  Kesediaan negara-negara ITRC untuk mematuhi ko...  "
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "evaluator = lambda x: evaluate(x)\r\n",
    "test_data1['result'] = pd.DataFrame(test_data1['cleaned_text'].apply(evaluator))\r\n",
    "test_data1.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permohonan ini juga bertujuan memohon penjelas...</td>\n",
       "      <td>1</td>\n",
       "      <td>Permohonan ini juga bertujuan memohon penjelas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Projek ini bukti komitmen berterusan kerajaan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Projek ini bukti komitmen berterusan kerajaan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menerusi pembentangan Bajet 2018 yang lalu, ke...</td>\n",
       "      <td>1</td>\n",
       "      <td>Menerusi pembentangan Bajet yang lalu kerajaan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berdasarkan kualiti jawapan calon, 27 peratus ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Berdasarkan kualiti jawapan calon peratus calo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pada masa sama, kerajaan negeri juga telah bua...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pada masa sama kerajaan negeri juga telah buat...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kita bawa pembangunan, bukan sahaja untuk Saba...</td>\n",
       "      <td>1</td>\n",
       "      <td>Kita bawa pembangunan bukan sahaja untuk Sabah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harapan kita agar isu berkaitan golongan muda ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Harapan kita agar isu berkaitan golongan muda ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kesan daripada penyemakan ini antaranya membab...</td>\n",
       "      <td>0</td>\n",
       "      <td>Kesan daripada penyemakan ini antaranya membab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kalau dah bersara dan tiada kaitan lagi dengan...</td>\n",
       "      <td>1</td>\n",
       "      <td>Kalau dah bersara dan tiada kaitan lagi dengan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kesediaan negara-negara ITRC untuk mematuhi ko...</td>\n",
       "      <td>1</td>\n",
       "      <td>Kesediaan negara-negara ITRC untuk mematuhi ko...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Permohonan ini juga bertujuan memohon penjelas...      1   \n",
       "1  Projek ini bukti komitmen berterusan kerajaan ...      1   \n",
       "2  Menerusi pembentangan Bajet 2018 yang lalu, ke...      1   \n",
       "3  Berdasarkan kualiti jawapan calon, 27 peratus ...      0   \n",
       "4  Pada masa sama, kerajaan negeri juga telah bua...      1   \n",
       "5  Kita bawa pembangunan, bukan sahaja untuk Saba...      1   \n",
       "6  Harapan kita agar isu berkaitan golongan muda ...      1   \n",
       "7  Kesan daripada penyemakan ini antaranya membab...      0   \n",
       "8  Kalau dah bersara dan tiada kaitan lagi dengan...      1   \n",
       "9  Kesediaan negara-negara ITRC untuk mematuhi ko...      1   \n",
       "\n",
       "                                        cleaned_text  result  \n",
       "0  Permohonan ini juga bertujuan memohon penjelas...       0  \n",
       "1  Projek ini bukti komitmen berterusan kerajaan ...       1  \n",
       "2  Menerusi pembentangan Bajet yang lalu kerajaan...       1  \n",
       "3  Berdasarkan kualiti jawapan calon peratus calo...      -1  \n",
       "4  Pada masa sama kerajaan negeri juga telah buat...      -1  \n",
       "5  Kita bawa pembangunan bukan sahaja untuk Sabah...       0  \n",
       "6  Harapan kita agar isu berkaitan golongan muda ...       1  \n",
       "7  Kesan daripada penyemakan ini antaranya membab...       0  \n",
       "8  Kalau dah bersara dan tiada kaitan lagi dengan...       1  \n",
       "9  Kesediaan negara-negara ITRC untuk mematuhi ko...       1  "
      ]
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score, f1_score, recall_score\r\n",
    "\r\n",
    "def sentiment_model_predict(data_test_target,data_prediction):\r\n",
    "    conf_matrix = confusion_matrix(data_test_target,data_prediction)\r\n",
    "    acc_score = accuracy_score(data_test_target, data_prediction)\r\n",
    "    pre_score = precision_score(data_test_target, data_prediction, average=\"macro\")\r\n",
    "    re_score = recall_score(data_test_target, data_prediction, average=\"macro\")\r\n",
    "    f_score = f1_score(data_test_target, data_prediction, average=\"macro\")\r\n",
    "\r\n",
    "    print(\"Accuracy : \"+str(round(acc_score*100,2)))\r\n",
    "    print(\"Precision : \"+str(round(pre_score*100,2)))\r\n",
    "    print(\"Recall : \"+str(round(re_score*100,2)))\r\n",
    "    print(\"F1-Score :\"+str(round(f_score*100,2)))\r\n",
    "    print(conf_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "actual = test_data1['label']\r\n",
    "predict = test_data1['result']\r\n",
    "\r\n",
    "sentiment_model_predict(actual,predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy : 47.1\n",
      "Precision : 46.11\n",
      "Recall : 47.48\n",
      "F1-Score :44.93\n",
      "[[468 245 181]\n",
      " [226 330 190]\n",
      " [566 543 939]]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "63428b703f7f2202de1c7eea6b1ed7afa0ebfa9bbee64a08b1fafe9e7c1519da"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}